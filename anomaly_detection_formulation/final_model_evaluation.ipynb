{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,roc_auc_score,roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import cross_val_score, learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'Dataset/new_feature_csv'\n",
    "regular_data = []\n",
    "attack_data = []\n",
    "for subfolder in os.listdir(directory_path):\n",
    "    subfolder_path = os.path.join(directory_path, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                file_path = os.path.join(subfolder_path, filename)\n",
    "                df = pd.read_csv(file_path)\n",
    "                if subfolder == 'Regular':\n",
    "                    df['Label'] = -1\n",
    "                    regular_data.append(df)\n",
    "                else:\n",
    "                    df['Label'] = 1\n",
    "                    attack_data.append(df)\n",
    "all_regular_raw_data = pd.concat(regular_data, ignore_index=True)\n",
    "all_attack_raw_data = pd.concat(attack_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regular_data_sh=shuffle(all_regular_raw_data, random_state=42)\n",
    "all_attack_data_sh=shuffle(all_attack_raw_data, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regular, X_remaining_regular = train_test_split(all_regular_data_sh, test_size=0.40, random_state=42)\n",
    "X_validation_regular, X_test_regular = train_test_split(X_remaining_regular, test_size=0.50, random_state=42)\n",
    "X_validation_attack, X_remaining_attack = train_test_split(all_attack_data_sh, test_size=0.80, random_state=42)\n",
    "X_test_combined = pd.concat([X_test_regular, X_remaining_attack], ignore_index=True)\n",
    "X_test_combined_sh = shuffle(X_test_combined, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr=X_train_regular[\"Label\"]\n",
    "y_te=X_test_combined_sh[\"Label\"]\n",
    "X_tr = X_train_regular.drop('Label', axis=1)\n",
    "X_te = X_test_combined_sh.drop('Label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('pca', PCA(n_components=0.95)) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pipeline.fit_transform(X_tr)\n",
    "X_test_pca = pipeline.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine The Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_filename = \"best_isolation_forest_50_0.75_0.01_0.5.pkl\"\n",
    "best_model = joblib.load(best_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(X, noise_level):\n",
    "    noise = np.random.normal(0, noise_level, X.shape)\n",
    "    X_noisy = X + noise\n",
    "    return X_noisy\n",
    "def add_drift(X, shift_factor):\n",
    "    sdv = 0.1\n",
    "    drift = np.random.normal(shift_factor, sdv, X.shape)\n",
    "    X_drift=X + drift\n",
    "    return X_drift\n",
    "def performance_evalidation(y,pred):\n",
    "    accuracy = accuracy_score(y, pred)\n",
    "    precision = precision_score(y, pred)\n",
    "    recall = recall_score(y, pred)\n",
    "    f1 = f1_score(y, pred)\n",
    "    roc_auc = roc_auc_score(y, pred)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print(f'ROC AUC: {roc_auc}')\n",
    "    conf_matrix = confusion_matrix(y, pred,labels=[1,-1])\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9984492863758192\n",
      "Precision: 0.9981545046047471\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9990764000526485\n",
      "ROC AUC: 0.9951925141413865\n",
      "Confusion Matrix:\n",
      "[[1332138       0]\n",
      " [   2463  253700]]\n"
     ]
    }
   ],
   "source": [
    "y_te_pred = -best_model.predict(X_test_pca)\n",
    "performance_evalidation(y_te,y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Robustness to Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9982471836257737\n",
      "Precision: 0.9979144848912521\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9989561539672899\n",
      "ROC AUC: 0.9945659599551847\n",
      "Confusion Matrix:\n",
      "[[1332138       0]\n",
      " [   2784  253379]]\n"
     ]
    }
   ],
   "source": [
    "noise_level_isof=0.1\n",
    "X_te_noisy_isof = add_noise(X_test_pca, noise_level_isof)\n",
    "y_isof_pred_noisy = -best_model.predict(X_te_noisy_isof)\n",
    "performance_evalidation(y_te,y_isof_pred_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drifting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9980759314512804\n",
      "Precision: 0.9977111940287329\n",
      "Recall: 1.0\n",
      "F1 Score: 0.998854285855679\n",
      "ROC AUC: 0.9940350479967832\n",
      "Confusion Matrix:\n",
      "[[1332138       0]\n",
      " [   3056  253107]]\n"
     ]
    }
   ],
   "source": [
    "shift_factor_isof=0.1\n",
    "X_te_drifted_isof = add_drift(X_test_pca, shift_factor_isof)\n",
    "y_isof_pred_drifted = -best_model.predict(X_te_drifted_isof)\n",
    "performance_evalidation(y_te,y_isof_pred_drifted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
